{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from doubleml import DoubleMLData, DoubleMLPLR\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Sample of Size 1000 for Double ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "\n",
    "# dimensions\n",
    "# sample size\n",
    "N = 1000\n",
    "\n",
    "# Yi: R, Xi: R^P, Zi: R^q\n",
    "p = 1\n",
    "q = 10\n",
    "\n",
    "# expanded design size\n",
    "NNp_ratio = 0.1\n",
    "Np = int(np.ceil(N / NNp_ratio))\n",
    "\n",
    "# number of repetitions\n",
    "num_reps = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "def r0(Z):\n",
    "    return np.cos(np.sum(Z**2, axis=1))\n",
    "\n",
    "\n",
    "def g0(Z):\n",
    "    return np.prod(np.exp(Z), axis=1)\n",
    "\n",
    "\n",
    "def f0(X):\n",
    "    beta_0 = 1\n",
    "    return X * beta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation variables\n",
    "seed = np.random.randint(0, 100)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# E: R^12, with Ej ~ Uniform[0, 1/2]\n",
    "E = np.random.uniform(0, 1/q, size=(N+1, q+2))\n",
    "# Zij = (Ej+1 + rho * E12) / (1 + rho)\n",
    "rho = 1\n",
    "Zt = ((E[:, 1:11] + rho * E[:, 11].reshape(-1, 1)) / (1 + rho))\n",
    "Z = Zt[1:, :]\n",
    "Z0 = Zt[0, :].reshape(1, -1)\n",
    "\n",
    "# or Xi = r0(Zi) + Vi\n",
    "V = np.random.normal(0, 1, size=(N,))\n",
    "X = r0(Z) + V\n",
    "\n",
    "# Yi = f0(Xi) + g0(Z_i) + Ui\n",
    "U = np.random.normal(0, 1, size=(N,))\n",
    "Y = f0(X) + g0(Z) + U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== DoubleMLData Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['d']\n",
      "Covariates: ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 1000\n",
      "\n",
      "------------------ DataFrame info    ------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Columns: 12 entries, X1 to d\n",
      "dtypes: float64(12)\n",
      "memory usage: 93.9 KB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define data for double ML\n",
    "dml_data = DoubleMLData.from_arrays(Z, Y, X)\n",
    "print(dml_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== DoubleMLPLR Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['d']\n",
      "Covariates: ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 1000\n",
      "\n",
      "------------------ Score & algorithm ------------------\n",
      "Score function: partialling out\n",
      "\n",
      "------------------ Machine learner   ------------------\n",
      "Learner ml_l: LinearRegression()\n",
      "Learner ml_m: LinearRegression()\n",
      "Out-of-sample Performance:\n",
      "Regression:\n",
      "Learner ml_l RMSE: [[1.48709269]]\n",
      "Learner ml_m RMSE: [[1.00309215]]\n",
      "\n",
      "------------------ Resampling        ------------------\n",
      "No. folds: 10\n",
      "No. repeated sample splits: 1\n",
      "\n",
      "------------------ Fit summary       ------------------\n",
      "       coef   std err          t          P>|t|    2.5 %    97.5 %\n",
      "d  1.040381  0.035486  29.318085  6.100561e-189  0.97083  1.109933\n"
     ]
    }
   ],
   "source": [
    "# Double ML using linear regression\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Define linear regression models\n",
    "ols_learner = LinearRegression()\n",
    "ols_g_hat = clone(ols_learner)  # Yi = f0(Xi) + g0(Z_i) + Ui\n",
    "ols_r_hat = clone(ols_learner)  # Xi = r0(Zi) + Vi\n",
    "\n",
    "# Initialize LinearDML with OLS models\n",
    "dml_ols = DoubleMLPLR(dml_data, ml_l=ols_g_hat, ml_m=ols_r_hat, n_folds=10)\n",
    "\n",
    "# Fit the model\n",
    "dml_ols.fit(store_models=True)\n",
    "print(dml_ols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== DoubleMLPLR Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['d']\n",
      "Covariates: ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 1000\n",
      "\n",
      "------------------ Score & algorithm ------------------\n",
      "Score function: partialling out\n",
      "\n",
      "------------------ Machine learner   ------------------\n",
      "Learner ml_l: RandomForestRegressor(n_estimators=10)\n",
      "Learner ml_m: RandomForestRegressor(n_estimators=10)\n",
      "Out-of-sample Performance:\n",
      "Regression:\n",
      "Learner ml_l RMSE: [[1.59688187]]\n",
      "Learner ml_m RMSE: [[1.0847613]]\n",
      "\n",
      "------------------ Resampling        ------------------\n",
      "No. folds: 10\n",
      "No. repeated sample splits: 1\n",
      "\n",
      "------------------ Fit summary       ------------------\n",
      "       coef   std err         t          P>|t|    2.5 %    97.5 %\n",
      "d  0.908012  0.040053  22.67029  8.801177e-114  0.82951  0.986515\n"
     ]
    }
   ],
   "source": [
    "# Double ML using random forest\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Define random forest models\n",
    "rf_learner = RandomForestRegressor(n_estimators=q)\n",
    "rf_g_hat = clone(rf_learner)  # Yi = f0(Xi) + g0(Z_i) + Ui\n",
    "rf_r_hat = clone(rf_learner)  # Xi = r0(Zi) + Vi\n",
    "\n",
    "# Initialize LinearDML with random forest models\n",
    "dml_rf = DoubleMLPLR(dml_data, ml_l=rf_g_hat, ml_m=rf_r_hat, n_folds=10)\n",
    "\n",
    "# Fit the model\n",
    "dml_rf.fit(store_models=True)\n",
    "print(dml_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== DoubleMLPLR Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['d']\n",
      "Covariates: ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10']\n",
      "Instrument variable(s): None\n",
      "No. Observations: 1000\n",
      "\n",
      "------------------ Score & algorithm ------------------\n",
      "Score function: partialling out\n",
      "\n",
      "------------------ Machine learner   ------------------\n",
      "Learner ml_l: MLPRegressor(hidden_layer_sizes=(128, 64, 64, 128), max_iter=5000,\n",
      "             random_state=4)\n",
      "Learner ml_m: MLPRegressor(hidden_layer_sizes=(128, 64, 64, 128), max_iter=5000,\n",
      "             random_state=4)\n",
      "Out-of-sample Performance:\n",
      "Regression:\n",
      "Learner ml_l RMSE: [[1.47493188]]\n",
      "Learner ml_m RMSE: [[0.99593571]]\n",
      "\n",
      "------------------ Resampling        ------------------\n",
      "No. folds: 10\n",
      "No. repeated sample splits: 1\n",
      "\n",
      "------------------ Fit summary       ------------------\n",
      "       coef   std err         t          P>|t|     2.5 %    97.5 %\n",
      "d  1.034341  0.035578  29.07237  8.026175e-186  0.964609  1.104073\n"
     ]
    }
   ],
   "source": [
    "# Double ML using NN\n",
    "nn_learner = MLPRegressor( \n",
    "    hidden_layer_sizes=(128, 64, 64, 128),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    max_iter=5000,\n",
    "    random_state=seed,\n",
    ")\n",
    "# Define neural network models\n",
    "nn_g_hat = clone(nn_learner)  # Yi = f0(Xi) + g0(Z_i) + Ui\n",
    "nn_r_hat = clone(nn_learner)  # Xi = r0(Zi) + Vi\n",
    "\n",
    "# Initialize LinearDML with neural networks\n",
    "dml_nn = DoubleMLPLR(dml_data, ml_l=nn_g_hat, ml_m=nn_r_hat, n_folds=10)\n",
    "\n",
    "# Fit the model\n",
    "dml_nn.fit(store_models=True)\n",
    "print(dml_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0403813798715436 0.9080122783131876 1.0343408633525129\n"
     ]
    }
   ],
   "source": [
    "print(dml_ols.coef[0], dml_rf.coef[0], dml_nn.coef[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanded Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "# Zi' = Zi + epsi\n",
    "Eps = np.random.normal(0, 1/q, (Np, q))\n",
    "Zp = Z0 + Eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CI_r0_round(Z, X, Z0, Zp, r_hat, alpha=0.05, seed=0):\n",
    "    r_hat.fit(Z, X)\n",
    "    X_hat = r_hat.predict(Z)\n",
    "    X_hatp = r_hat.predict(Zp)\n",
    "    \n",
    "    mean_X_hatp = np.mean(X_hatp)\n",
    "    delta = np.mean(X_hat - X)\n",
    "    sigma_hat1 = np.mean((X_hat - X - delta) ** 2)\n",
    "    sigma_hat2 = np.mean((X_hatp - mean_X_hatp) ** 2)\n",
    "\n",
    "    def w_theta(alpha):\n",
    "        return scipy.stats.norm.ppf(1 - alpha / (2 * p)) * np.sqrt(\n",
    "            sigma_hat1 / N + sigma_hat2 / Np\n",
    "        )\n",
    "\n",
    "    def CI_r0(alpha):\n",
    "        w = w_theta(alpha)\n",
    "        lower = mean_X_hatp - delta - w\n",
    "        upper = mean_X_hatp - delta + w\n",
    "        return [lower, upper]\n",
    "\n",
    "    def does_CI_cover(CI, truth):\n",
    "        if truth > CI[0] and truth < CI[1]:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    print(CI_r0(alpha))\n",
    "    print(r0(Z0))\n",
    "    return does_CI_cover(CI_r0(alpha), r0(Z0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0050560987509412, 1.1294946668400085]\n",
      "[0.99985939]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CI_r0_round(Z, X, Z0, Zp, ols_r_hat, alpha=0.05, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8137977499456142, 0.874283497983563]\n",
      "[0.99985939]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CI_r0_round(Z, X, Z0, Zp, rf_r_hat, alpha=0.05, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9434907677072256, 1.0668945144056228]\n",
      "[0.99985939]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CI_r0_round(Z, X, Z0, Zp, nn_r_hat, alpha=0.05, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03724587 0.05851847 0.04562505 0.04477069 0.02068873 0.05869798\n",
      "  0.01019577 0.02253337 0.03162383 0.0488534 ]]\n"
     ]
    }
   ],
   "source": [
    "print(Z0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kte_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
